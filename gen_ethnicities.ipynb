{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "# input\n",
    "DATA_FOLDER = './data/'\n",
    "MOVIES_FOLDER = DATA_FOLDER + 'movies_summaries/'\n",
    "CHARACTERS_FILE = MOVIES_FOLDER + 'character.metadata.tsv'\n",
    "\n",
    "# output\n",
    "ETHNICITY_FILE = './gen/ethnicities.txt'\n",
    "\n",
    "# import characters dataset\n",
    "character_columns = ['wiki_movie_id', 'freebase_movie_id', 'm_release_date', 'name', 'a_dob', 'a_gender', 'a_height', 'a_ethnicity_freebase_id', 'a_name', 'a_age_at_release', 'freebase_char/a_map', 'freebase_char_id', 'freebase_a_id']\n",
    "characters = pd.read_csv(CHARACTERS_FILE, sep='\\t', names=character_columns, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data generated in ./gen/ethnicities.txt\n"
     ]
    }
   ],
   "source": [
    "def get_ethnicities(ethnicities_id):    \n",
    "    \"\"\"\n",
    "        Recover ethnicity names from freebase id's using sparql query\n",
    "\n",
    "        :enthicities_id: list of freebase id's\n",
    "    \"\"\"\n",
    "    url = \"https://query.wikidata.org/bigdata/namespace/wdq/sparql\"\n",
    "\n",
    "    query = '''\n",
    "        PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "        PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "        PREFIX wikibase: <http://wikiba.se/ontology#>\n",
    "\n",
    "        SELECT  ?s ?sLabel ?p  ?o ?oLabel WHERE {{\n",
    "            {}\n",
    "\n",
    "            SERVICE wikibase:label {{\n",
    "                bd:serviceParam wikibase:language \"en\" .\n",
    "            }}\n",
    "        }}\n",
    "    '''\n",
    "\n",
    "    # add every id in UNION\n",
    "    ethnicities_id = ethnicities_id.apply(lambda x: '{{?s wdt:P646 \"{}\"}}'.format(x))\n",
    "    ethnicities_id.iloc[1:] = ethnicities_id.iloc[1:].apply(lambda x: ' UNION ' + x)\n",
    "\n",
    "    query = query.format(ethnicities_id.str.cat())\n",
    "    response = requests.get(url, params = {'format': 'json', 'query': query})\n",
    "    return response\n",
    "\n",
    "# get all unique ethnicity id's\n",
    "ethnicities_id = pd.Series(characters['a_ethnicity_freebase_id'].unique())\n",
    "ethnicities_id = ethnicities_id.iloc[1:] # remove nan\n",
    "\n",
    "# We cannot query all id's at once. We need to split the query in multiple requests.\n",
    "ethnicities = []\n",
    "idx_ranges = np.linspace(0, ethnicities_id.size, 5, dtype=int)\n",
    "\n",
    "for i in range(1, len(idx_ranges)):\n",
    "    idx_range = np.arange(idx_ranges[i-1], idx_ranges[i])\n",
    "    response = get_ethnicities(ethnicities_id.iloc[idx_range])\n",
    "\n",
    "    # add all results to the list\n",
    "    results = response.json()\n",
    "    for res in results['results']['bindings']:\n",
    "        ethnicities.append(res['sLabel']['value'])\n",
    "\n",
    "# values which don't have information\n",
    "undefined_values = ['Q31340083', 'Q97377726', 'Q54864438', 'Q56408633', 'Q25467191']\n",
    "\n",
    "with open(ETHNICITY_FILE, 'w', encoding='utf-8') as f:\n",
    "    for ethnicity in ethnicities:\n",
    "        if ethnicity not in undefined_values:\n",
    "            f.write(\"{}\\n\".format(ethnicity))\n",
    "\n",
    "print(\"Data generated in {}\".format(ETHNICITY_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matching found for /m/044038p\n",
      "Sleeping for 10 seconds...\n",
      "Elements treated: 0\n",
      "Sleeping for 10 seconds...\n",
      "Elements treated: 10\n",
      "No matching found for /m/02p1pl6\n",
      "No matching found for /m/0bjbszh\n",
      "No matching found for /m/075dhf0\n",
      "Sleeping for 10 seconds...\n",
      "Elements treated: 20\n",
      "Sleeping for 10 seconds...\n",
      "Elements treated: 30\n",
      "No matching found for /m/092h2qt\n",
      "Sleeping for 10 seconds...\n",
      "Elements treated: 40\n",
      "Sleeping for 10 seconds...\n",
      "Elements treated: 50\n",
      "No matching found for /m/04kbvpz\n",
      "No matching found for /m/03ftx7\n",
      "Sleeping for 10 seconds...\n",
      "Elements treated: 60\n",
      "No matching found for /m/0747611\n",
      "No matching found for /m/047l_90\n",
      "Sleeping for 10 seconds...\n",
      "Elements treated: 70\n",
      "Sleeping for 10 seconds...\n",
      "Elements treated: 80\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def get_one_ethnicity(ethnicity_id):    \n",
    "    \"\"\"\n",
    "        Recover ethnicity names from freebase id's using sparql query\n",
    "\n",
    "        :enthicities_id: list of freebase id's\n",
    "    \"\"\"\n",
    "    url = \"https://query.wikidata.org/bigdata/namespace/wdq/sparql\"\n",
    "\n",
    "    query = '''\n",
    "        PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "        PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "        PREFIX wikibase: <http://wikiba.se/ontology#>\n",
    "\n",
    "        SELECT  ?s ?sLabel ?p  ?o ?oLabel WHERE {{\n",
    "            {}\n",
    "\n",
    "            SERVICE wikibase:label {{\n",
    "                bd:serviceParam wikibase:language \"en\" .\n",
    "            }}\n",
    "        }}\n",
    "    '''\n",
    "\n",
    "    # add every id in UNION\n",
    "    ethnicity_id = '{{?s wdt:P646 \"{}\"}}'.format(ethnicity_id)\n",
    "    query = query.format(ethnicity_id)\n",
    "\n",
    "    response = requests.get(url, params = {'format': 'json', 'query': query})\n",
    "    return response\n",
    "\n",
    "ethnicities = {}\n",
    "for i, ethnicity_id in enumerate(ethnicities_id):\n",
    "    response = get_one_ethnicity(ethnicity_id)\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        if len(result['results']['bindings']) > 0:\n",
    "            ethnicities[ethnicity_id] = result['results']['bindings'][0]['sLabel']['value']\n",
    "        else:\n",
    "            print(\"No matching found for {}\".format(ethnicity_id))\n",
    "    else:\n",
    "        print(\"Error: {}\".format(response.status_code))\n",
    "        print(\"Line: {}\".format(i))\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(\"Sleeping for 10 seconds...\")\n",
    "        print(\"Elements treated: {}\".format(i))\n",
    "        time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ETHNICITY_FILE, 'w', encoding='utf-8') as f:\n",
    "    for freebase_id, ethnicity in ethnicities.items():\n",
    "        if ethnicity not in undefined_values:\n",
    "            f.write(\"{}\\t{}\\n\".format(freebase_id, ethnicity))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b7477865c3b10d64ced3258d391994d31c5d5216fb1f6f71b5cb53c89252681"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
